{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f65ea5-97ad-4cb1-8a44-a5bc59a3342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = 'data_path'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becacfbc-960c-427f-9882-95bf019fed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data for training\n",
    "df = df.drop([insert columns after 1st trimester], axis=1)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ede707-ebb7-4101-961f-fde3b97c3f3c",
   "metadata": {},
   "source": [
    "# General Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b32bb-ac28-49ba-b8b3-222406e805e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "full_df = df\n",
    "# 'GDM' is the target variable\n",
    "target_column = 'GDM'\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = full_df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = full_df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_features.remove(target_column)\n",
    "numerical_features.remove('ID')\n",
    "\n",
    "# Preprocessor setup\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Include columns not specified in transformers unchanged\n",
    ")\n",
    "\n",
    "# Apply preprocessing to the entire dataset except 'ID' and 'GDM'\n",
    "features = full_df.drop([target_column, 'ID'], axis=1)\n",
    "X_processed = preprocessor.fit_transform(features)\n",
    "y = full_df[target_column].values\n",
    "\n",
    "# Convert processed features back to DataFrame with transformed column names\n",
    "columns_transformed = (list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    "                       + numerical_features)\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=columns_transformed)\n",
    "\n",
    "# Reattach 'ID' to processed features for grouping in splits\n",
    "X_processed_df['ID'] = full_df['ID'].values\n",
    "\n",
    "# Initial group-based split\n",
    "# This is to ensure that all ID are in the same set\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "train_idxs, temp_idxs = next(gss.split(X_processed_df, groups=X_processed_df['ID']))\n",
    "train_set = X_processed_df.iloc[train_idxs]\n",
    "y_train = y[train_idxs]\n",
    "temp_set = X_processed_df.iloc[temp_idxs]\n",
    "y_temp = y[temp_idxs]\n",
    "\n",
    "# Split temp set into validation and test sets\n",
    "gss_temp = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=42)\n",
    "val_idxs, test_idxs = next(gss_temp.split(temp_set, groups=temp_set['ID']))\n",
    "validation_set = temp_set.iloc[val_idxs]\n",
    "y_val = y_temp[val_idxs]\n",
    "test_set = temp_set.iloc[test_idxs]\n",
    "y_test = y_temp[test_idxs]\n",
    "\n",
    "# Separate features from 'ID' for training, validation, and test sets\n",
    "X_train = train_set.drop('ID', axis=1)\n",
    "X_val = validation_set.drop('ID', axis=1)\n",
    "X_test = test_set.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a855cc3-2b06-4ccc-8ef8-9668b0c78e9c",
   "metadata": {},
   "source": [
    "# General Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae78fdc-92be-4fbc-9739-f8650b82a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, f1_score, brier_score_loss\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Assuming X_train, X_val, y_train, y_val are already defined\n",
    "# Define the parameter distributions for the RandomizedSearchCV for each model\n",
    "param_distributions = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5, 10]\n",
    "    },\n",
    "    'ExplainableBoostingClassifier': {\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'max_leaves': [3, 10, 20]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'XGBClassifier': XGBClassifier(eval_metric='logloss'),\n",
    "    'ExplainableBoostingClassifier': ExplainableBoostingClassifier()\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "roc_results = {}\n",
    "ap_results = {}\n",
    "metrics_results = {}  # Dictionary to store all the additional metrics\n",
    "calibration_data = {}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstraps=1000, ci=0.95, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    bootstrapped_scores = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.choice(range(len(y_score)), size=len(y_score), replace=True)\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        score = roc_auc_score(y_true[indices], y_score[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "    lower = sorted_scores[int((1.0 - ci) / 2 * len(sorted_scores))]\n",
    "    upper = sorted_scores[int((1.0 + ci) / 2 * len(sorted_scores))]\n",
    "    return lower, upper\n",
    "    \n",
    "for name, model in models.items():\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_distributions[name], n_iter=10, scoring='roc_auc', n_jobs=-1, \n",
    "                                       cv=stratified_kfold, verbose=1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_estimators[name] = random_search.best_estimator_\n",
    "    \n",
    "    # Predict probabilities for the validation set\n",
    "    y_score = best_estimators[name].predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Compute ROC AUC\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_ci_lower, auc_ci_upper = bootstrap_auc_ci(np.array(y_val), np.array(y_score))\n",
    "    roc_results[name] = (fpr, tpr, roc_auc, auc_ci_lower, auc_ci_upper)\n",
    "    \n",
    "    # Compute Average Precision\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_score)\n",
    "    ap_score = average_precision_score(y_val, y_score)\n",
    "    ap_results[name] = (precision, recall, ap_score)\n",
    "\n",
    "    # Convert probabilities to binary predictions using 0.5 threshold\n",
    "    y_pred = (y_score >= 0.5).astype(int)\n",
    "    \n",
    "    # Compute Confusion Matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    \n",
    "    # Compute Sensitivity (Recall for Positive Class)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Compute Specificity\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Compute F1 Score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    # Compute Brier Score\n",
    "    brier = brier_score_loss(y_val, y_score)\n",
    "    \n",
    "    # Store the computed metrics\n",
    "    metrics_results[name] = {\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'F1 Score': f1,\n",
    "        'Brier Score': brier\n",
    "    }\n",
    "    \n",
    "    # Calibration slope & intercept\n",
    "    calib_lr = LogisticRegression(solver='lbfgs')\n",
    "    eps = 1e-15\n",
    "    y_score_clipped = np.clip(y_score, eps, 1 - eps)\n",
    "    logit_y_score = np.log(y_score_clipped / (1 - y_score_clipped))\n",
    "    calib_lr.fit(logit_y_score.reshape(-1, 1), y_val)\n",
    "    calib_intercept = calib_lr.intercept_[0]\n",
    "    calib_slope = calib_lr.coef_[0][0]\n",
    "\n",
    "    # O:E ratio\n",
    "    expected_positives = np.sum(y_score)\n",
    "    observed_positives = np.sum(y_val)\n",
    "    oe_ratio = observed_positives / expected_positives if expected_positives != 0 else np.nan\n",
    "\n",
    "    # Update calibration_data\n",
    "    calibration_data[name] = {\n",
    "        'y_true': y_val,\n",
    "        'y_pred_prob': y_score,\n",
    "        'Calibration Intercept': calib_intercept,\n",
    "        'Calibration Slope': calib_slope,\n",
    "        'O:E Ratio': oe_ratio\n",
    "    }\n",
    "\n",
    "# After training all models, you can print or log the results\n",
    "for name in models.keys():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"Best Estimator: {best_estimators[name]}\")\n",
    "    print(f\"ROC AUC: {roc_results[name][2]:.3f}\")\n",
    "    print(f\"Average Precision (AP): {ap_results[name][2]:.3f}\")\n",
    "    print(f\"Sensitivity: {metrics_results[name]['Sensitivity']:.3f}\")\n",
    "    print(f\"Specificity: {metrics_results[name]['Specificity']:.3f}\")\n",
    "    print(f\"F1 Score: {metrics_results[name]['F1 Score']:.3f}\")\n",
    "    print(f\"Brier Score: {metrics_results[name]['Brier Score']:.3f}\")\n",
    "    print(f\"ROC AUC: {roc_results[name][2]:.3f} (95% CI: {roc_results[name][3]:.3f} – {roc_results[name][4]:.3f})\")\n",
    "    print(f\"Calibration Slope: {calibration_data[name]['Calibration Slope']:.3f}\")\n",
    "    print(f\"Calibration Intercept: {calibration_data[name]['Calibration Intercept']:.3f}\")\n",
    "    print(f\"O:E Ratio: {calibration_data[name]['O:E Ratio']:.3f}\")\n",
    "\n",
    "# Save the results using joblib\n",
    "from joblib import dump\n",
    "results = {\n",
    "    'best_estimators': best_estimators,\n",
    "    'roc_results': roc_results,\n",
    "    'ap_results': ap_results,\n",
    "    'metrics_results': metrics_results,\n",
    "    'calibration_data': calibration_data\n",
    "}\n",
    "dump(results, 'model_results.joblib')\n",
    "print(\"Model results saved to 'model_results.joblib'.\")\n",
    "    \n",
    "plt.rcParams.update({'font.size': 14, 'figure.dpi': 100})\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 10))\n",
    "for name, (fpr, tpr, roc_auc, auc_ci_lower, auc_ci_upper) in roc_results.items():\n",
    "    plt.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curves\n",
    "plt.figure(figsize=(10, 10))\n",
    "for name, (precision, recall, ap_score) in ap_results.items():\n",
    "    plt.plot(recall, precision, label=f'{name} (AP = {ap_score:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65d687-40cb-45e3-a21b-1a8cd229c0e7",
   "metadata": {},
   "source": [
    "## Repeat above steps for Nulliparous Model and FTP-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b67c039-ce65-40f4-ac95-4a29fb45071e",
   "metadata": {},
   "source": [
    "## FTP-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a371e2f-b71d-4814-bcf0-5cb539f5478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[['ID','Ethnic Origin of Patient','Age at booking', 'Hx_GDM', 'BMI', 'FH Diabetes',\n",
    "             'Other Endocrine probs', 'Systolic BP at booking', 'Diastolic BP at booking', 'Parity (not inc.multiple)',\n",
    "             'GDM']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8637eb-da33-43f0-bb95-748001b36d8c",
   "metadata": {},
   "source": [
    "## Nulliparous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37976cb-1e28-4353-8d17-1679e103f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = df[df['Parity (not inc.multiple)'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a14c8e-5668-4bec-b91e-0e4746d9a792",
   "metadata": {},
   "source": [
    "# Sequential Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8b0e2-ff9d-478d-be42-86f8602addc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert 'Date of Birth' to datetime\n",
    "df['Date of Birth'] = pd.to_datetime(df['Date of Birth'])\n",
    "\n",
    "# Sort by 'ID' and 'Date of Birth' so that they are together\n",
    "df = df.sort_values(by=['ID', 'Date of Birth'])\n",
    "\n",
    "# Create a shifted column to get the future pregnancy 'GDM' status.\n",
    "# This shifts the 'GDM' values by one row upwards within each group.\n",
    "df['future_GDM'] = df.groupby('ID')['GDM'].shift(-1)\n",
    "\n",
    "# Drop rows where there is no future pregnancy data\n",
    "df = df.dropna(subset=['future_GDM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055e35e-e942-434a-a5b3-4f9395e01148",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9a634-c193-418e-9e71-ca163c7ee542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 'GDM' is the target variable\n",
    "target_column = 'future_GDM'\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_features.remove(target_column)\n",
    "numerical_features.remove('ID')\n",
    "\n",
    "# Preprocessor setup\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Include columns not specified in transformers unchanged\n",
    ")\n",
    "\n",
    "# Apply preprocessing to the entire dataset except 'ID' and 'GDM'\n",
    "features = df.drop([target_column, 'ID'], axis=1)\n",
    "X_processed = preprocessor.fit_transform(features)\n",
    "y = df[target_column].values\n",
    "\n",
    "# Convert processed features back to DataFrame with transformed column names\n",
    "columns_transformed = (list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    "                       + numerical_features)\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=columns_transformed)\n",
    "\n",
    "# Reattach 'ID' to processed features for grouping in splits\n",
    "X_processed_df['ID'] = df['ID'].values\n",
    "\n",
    "# Initial group-based split\n",
    "# This is to ensure that all patients are in the same set\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "train_idxs, temp_idxs = next(gss.split(X_processed_df, groups=X_processed_df['ID']))\n",
    "train_set = X_processed_df.iloc[train_idxs]\n",
    "y_train = y[train_idxs]\n",
    "temp_set = X_processed_df.iloc[temp_idxs]\n",
    "y_temp = y[temp_idxs]\n",
    "\n",
    "# Split temp set into validation and test sets\n",
    "gss_temp = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=42)\n",
    "val_idxs, test_idxs = next(gss_temp.split(temp_set, groups=temp_set['ID']))\n",
    "validation_set = temp_set.iloc[val_idxs]\n",
    "y_val = y_temp[val_idxs]\n",
    "test_set = temp_set.iloc[test_idxs]\n",
    "y_test = y_temp[test_idxs]\n",
    "\n",
    "# Separate features from 'ID' for training, validation, and test sets\n",
    "X_train = train_set.drop('ID', axis=1)\n",
    "X_val = validation_set.drop('ID', axis=1)\n",
    "X_test = test_set.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de0a59-9e82-4b0b-a425-c4be133663fb",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e755b96-7d7f-4f1a-adbd-5acf9cf17a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, f1_score, brier_score_loss, roc_auc_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train, X_val, y_train, y_val are already defined\n",
    "\n",
    "# Define the parameter distributions for the RandomizedSearchCV for each model\n",
    "param_distributions = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5, 10]\n",
    "    },\n",
    "    'ExplainableBoostingClassifier': {\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'max_leaves': [3, 10, 20]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'XGBClassifier': XGBClassifier(eval_metric='logloss'),\n",
    "    'ExplainableBoostingClassifier': ExplainableBoostingClassifier()\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "roc_results = {}\n",
    "ap_results = {}\n",
    "metrics_results = {}  # Dictionary to store all the additional metrics\n",
    "calibration_data = {}\n",
    "\n",
    "# Define stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a bootstrap function to compute the 95% CI for the AUC\n",
    "def bootstrap_auc_ci(y_true, y_score, n_bootstraps=1000, ci=0.95, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    bootstrapped_scores = []\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.choice(range(len(y_score)), size=len(y_score), replace=True)\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        score = roc_auc_score(y_true[indices], y_score[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "    lower = sorted_scores[int((1.0 - ci) / 2 * len(sorted_scores))]\n",
    "    upper = sorted_scores[int((1.0 + ci) / 2 * len(sorted_scores))]\n",
    "    return lower, upper\n",
    "\n",
    "for name, model in models.items():\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, \n",
    "        param_distributions=param_distributions[name], \n",
    "        n_iter=10, \n",
    "        scoring='roc_auc', \n",
    "        n_jobs=-1, \n",
    "        cv=skf, \n",
    "        verbose=1, \n",
    "        random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_estimators[name] = random_search.best_estimator_\n",
    "    \n",
    "    # Predict probabilities for the validation set\n",
    "    y_score = best_estimators[name].predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # --- Calibration Metrics ---\n",
    "    # Calibration slope & intercept\n",
    "    calib_lr = LogisticRegression(solver='lbfgs')\n",
    "    eps = 1e-15\n",
    "    y_score_clipped = np.clip(y_score, eps, 1 - eps)\n",
    "    logit_y_score = np.log(y_score_clipped / (1 - y_score_clipped))\n",
    "    calib_lr.fit(logit_y_score.reshape(-1, 1), y_val)\n",
    "    calib_intercept = calib_lr.intercept_[0]\n",
    "    calib_slope = calib_lr.coef_[0][0]\n",
    "    \n",
    "    expected_positives = np.sum(y_score)\n",
    "    observed_positives = np.sum(y_val)\n",
    "    oe_ratio = observed_positives / expected_positives if expected_positives != 0 else np.nan\n",
    "    \n",
    "    calibration_data[name] = {\n",
    "        'y_true': y_val,\n",
    "        'y_pred_prob': y_score,\n",
    "        'Calibration Intercept': calib_intercept,\n",
    "        'Calibration Slope': calib_slope,\n",
    "        'O:E Ratio': oe_ratio\n",
    "    }\n",
    "    \n",
    "    # --- ROC and Precision-Recall Metrics ---\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_ci_lower, auc_ci_upper = bootstrap_auc_ci(np.array(y_val), np.array(y_score))\n",
    "    roc_results[name] = (fpr, tpr, roc_auc, auc_ci_lower, auc_ci_upper)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_score)\n",
    "    ap_score = average_precision_score(y_val, y_score)\n",
    "    ap_results[name] = (precision, recall, ap_score)\n",
    "    \n",
    "    # Convert probabilities to binary predictions using a 0.5 threshold\n",
    "    y_pred = (y_score >= 0.5).astype(int)\n",
    "    \n",
    "    # Compute Confusion Matrix and additional metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    brier = brier_score_loss(y_val, y_score)\n",
    "    \n",
    "    metrics_results[name] = {\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'F1 Score': f1,\n",
    "        'Brier Score': brier\n",
    "    }\n",
    "    \n",
    "# After training all models, print the results\n",
    "for name in models.keys():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"Best Estimator: {best_estimators[name]}\")\n",
    "    print(f\"ROC AUC: {roc_results[name][2]:.3f} (95% CI: {roc_results[name][3]:.3f} – {roc_results[name][4]:.3f})\")\n",
    "    print(f\"Average Precision (AP): {ap_results[name][2]:.3f}\")\n",
    "    print(f\"Sensitivity: {metrics_results[name]['Sensitivity']:.3f}\")\n",
    "    print(f\"Specificity: {metrics_results[name]['Specificity']:.3f}\")\n",
    "    print(f\"F1 Score: {metrics_results[name]['F1 Score']:.3f}\")\n",
    "    print(f\"Brier Score: {metrics_results[name]['Brier Score']:.3f}\")\n",
    "    print(f\"Calibration Slope: {calibration_data[name]['Calibration Slope']:.3f}\")\n",
    "    print(f\"Calibration Intercept: {calibration_data[name]['Calibration Intercept']:.3f}\")\n",
    "    print(f\"O:E Ratio: {calibration_data[name]['O:E Ratio']:.3f}\")\n",
    "\n",
    "# Save the results using joblib\n",
    "from joblib import dump\n",
    "results = {\n",
    "    'best_estimators': best_estimators,\n",
    "    'roc_results': roc_results,\n",
    "    'ap_results': ap_results,\n",
    "    'metrics_results': metrics_results,\n",
    "    'calibration_data': calibration_data\n",
    "}\n",
    "dump(results, 'prev_model_results.joblib')\n",
    "print(\"Model results saved to 'prev_model_results.joblib'.\")\n",
    "\n",
    "plt.rcParams.update({'font.size': 14, 'figure.dpi': 100})\n",
    "\n",
    "# Plot ROC curves with confidence intervals in the legend\n",
    "plt.figure(figsize=(10, 10))\n",
    "for name, (fpr, tpr, roc_auc, auc_ci_lower, auc_ci_upper) in roc_results.items():\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f}, 95% CI = [{auc_ci_lower:.3f}, {auc_ci_upper:.3f}])')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curves\n",
    "plt.figure(figsize=(10, 10))\n",
    "for name, (precision, recall, ap_score) in ap_results.items():\n",
    "    plt.plot(recall, precision, label=f'{name} (AP = {ap_score:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
